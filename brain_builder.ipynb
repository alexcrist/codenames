{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "from gensim.models import KeyedVectors\n",
    "from pprint import pprint\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './models/GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    }
   ],
   "source": [
    "model = KeyedVectors.load_word2vec_format(model_path, binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_words = [\n",
    "    \"whip\",\n",
    "    \"wind\",\n",
    "    \"pole\",\n",
    "    \"life\",\n",
    "    \"washington\",\n",
    "    \"ray\",\n",
    "    \"tokyo\",\n",
    "    \"change\",\n",
    "    \"screen\",\n",
    "]\n",
    "blue_words = [\n",
    "    \"china\",\n",
    "    \"antarctica\",\n",
    "    \"stream\",\n",
    "    \"fighter\",\n",
    "    \"stone\",\n",
    "    \"space\",\n",
    "    \"spring\",\n",
    "    \"belt\",\n",
    "]\n",
    "neutral_words = [\n",
    "    \"buck\",\n",
    "    \"nurse\",\n",
    "    \"laser\",\n",
    "    \"ball\",\n",
    "    \"crane\",\n",
    "    \"revolution\",\n",
    "    \"mass\",\n",
    "]\n",
    "black_words = [\n",
    "    \"pan\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(*args, **kwargs):\n",
    "    \"\"\"Wrap gensim's most_similar function to filter similar words or n_grams.\n",
    "    \n",
    "    Use like:\n",
    "    most_similar(\n",
    "        positive = [\"belt\", \"stone\"],\n",
    "        negative = [\"buck\", \"nurse\"],\n",
    "        topn = 10\n",
    "    )\n",
    "    \n",
    "    \"\"\"\n",
    "    topn = kwargs.get(\"topn\", 10)\n",
    "    kwargs[\"topn\"] = topn + 20\n",
    "    words = model.most_similar(*args, **kwargs)\n",
    "    words = [(w.lower(), n) for w, n in words]\n",
    "    \n",
    "    exclude_substrings=True\n",
    "    if exclude_substrings:\n",
    "        input_words = kwargs[\"positive\"]\n",
    "        words = [\n",
    "            (w.lower(), n)\n",
    "            for w, n in words\n",
    "            if not (any(w in i_w for i_w in input_words) or\n",
    "                    any(i_w in w for i_w in input_words) or\n",
    "                    \"_\" in w)\n",
    "        ]\n",
    "    return words[:topn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function most_similar in module __main__:\n",
      "\n",
      "most_similar(*args, **kwargs)\n",
      "    Wrap gensim's most_similar function to filter similar words or n_grams.\n",
      "    \n",
      "    Use like:\n",
      "    most_similar(\n",
      "        positive = [\"belt\", \"stone\"],\n",
      "        negative = [\"buck\", \"nurse\"],\n",
      "        topn = 10\n",
      "    )\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(most_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('marble', 0.4827648401260376),\n",
       " ('granite', 0.47009357810020447),\n",
       " ('knapped', 0.4621773660182953),\n",
       " ('chedi', 0.45354604721069336),\n",
       " ('rocks', 0.4529286026954651),\n",
       " ('bricks', 0.44156622886657715),\n",
       " ('flint', 0.44095659255981445),\n",
       " ('brick', 0.43910306692123413),\n",
       " ('ring', 0.43649399280548096),\n",
       " ('lintels', 0.4330446124076843),\n",
       " ('fireclay', 0.4248562157154083),\n",
       " ('posthole', 0.4231618344783783)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(\n",
    "    positive = [\"belt\", \"stone\"],\n",
    "#     negative = [\"buck\", \"nurse\"],\n",
    "    topn = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_similarities(words, clue_size=2):\n",
    "    \"\"\"Compute the pairwise similarities for all words in the given `words` list.\"\"\"\n",
    "    word_pairs = []\n",
    "    for w1, w2 in combinations(words, r=clue_size):\n",
    "        # TODO: support more than 2 words here\n",
    "        # Do it by doing all pairwise similarities\n",
    "        # Then averaging them, and include the std dev of similarities for ref\n",
    "        word_pairs.append((w1, w2, model.similarity(w1, w2)))\n",
    "        \n",
    "    word_pairs = sorted(word_pairs, key=lambda v: v[2], reverse=True)\n",
    "    return word_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_words = [\"doubt\", \"surrender\", \"agreement\", \"avoid\", \"freeze\", \"election\", \"fleet\", \"shot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('surrender', 'freeze', 0.20315844),\n",
       " ('surrender', 'shot', 0.17242557),\n",
       " ('surrender', 'avoid', 0.17037044),\n",
       " ('agreement', 'freeze', 0.16948375),\n",
       " ('surrender', 'agreement', 0.14466019),\n",
       " ('surrender', 'election', 0.13724972),\n",
       " ('doubt', 'election', 0.1198404),\n",
       " ('doubt', 'agreement', 0.11001658),\n",
       " ('avoid', 'freeze', 0.10682899),\n",
       " ('doubt', 'fleet', 0.10228983),\n",
       " ('agreement', 'election', 0.09806852),\n",
       " ('agreement', 'fleet', 0.083731815),\n",
       " ('freeze', 'election', 0.071638785),\n",
       " ('doubt', 'shot', 0.066546075),\n",
       " ('avoid', 'election', 0.062058914),\n",
       " ('election', 'shot', 0.06052341),\n",
       " ('agreement', 'avoid', 0.052880652),\n",
       " ('election', 'fleet', 0.051850107),\n",
       " ('freeze', 'fleet', 0.048861697),\n",
       " ('doubt', 'surrender', 0.046274703),\n",
       " ('avoid', 'shot', 0.03572711),\n",
       " ('doubt', 'freeze', 0.020384984),\n",
       " ('surrender', 'fleet', 0.011949156),\n",
       " ('avoid', 'fleet', -0.0014913228),\n",
       " ('fleet', 'shot', -0.014988079),\n",
       " ('freeze', 'shot', -0.02550612),\n",
       " ('agreement', 'shot', -0.026432715),\n",
       " ('doubt', 'avoid', -0.032414127)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_all_similarities(in_words, clue_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jet', 0.5682516098022461),\n",
       " ('jetliner', 0.5431833863258362),\n",
       " ('aircraft', 0.5421854257583618),\n",
       " ('cessna', 0.5411485433578491),\n",
       " ('camembert', 0.5361970067024231),\n",
       " ('airliner', 0.5288451910018921),\n",
       " ('emmenthal', 0.5261411070823669),\n",
       " ('camembert', 0.5080846548080444),\n",
       " ('helicopter', 0.505513072013855),\n",
       " ('cheddar', 0.50484699010849),\n",
       " ('turboprop', 0.5037637948989868),\n",
       " ('jets', 0.5007143020629883),\n",
       " ('mozzarella', 0.49749767780303955),\n",
       " ('emmenthaler', 0.4910329282283783)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(positive=[\"cheese\", \"plane\"], topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5545972"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity(\"tokyo\", \"washington\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('belts', 0.465261310338974),\n",
       " ('spaces', 0.43275758624076843),\n",
       " ('Feustel_replied', 0.429858922958374),\n",
       " ('Shuttle_Atlantis_arrives', 0.42639511823654175),\n",
       " ('Shuttle_Discovery_blasts', 0.4256429374217987),\n",
       " ('black_grosgrain', 0.42392557859420776),\n",
       " ('Shuttle_docks', 0.42277610301971436),\n",
       " ('Shuttle_Endeavour_undocks', 0.4217846393585205),\n",
       " ('Shuttle_Discovery_docks', 0.41901007294654846),\n",
       " ('stowage_space', 0.4154626429080963)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Todo, see if this other similarity func is ever worth using\n",
    "model.most_similar_cosmul(positive=[\"space\", \"belt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stone'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar_to_given(\"china\", blue_words[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dist = [*zip(blue_words[1:], model.distances(\"china\", blue_words[1:]))]\n",
    "word_dist = sorted([(n, w) for w, n in word_dist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.70375335, 'stone'),\n",
       " (0.911139, 'antarctica'),\n",
       " (0.9438042, 'space'),\n",
       " (0.952535, 'belt'),\n",
       " (0.9542776, 'fighter'),\n",
       " (0.9791071, 'spring'),\n",
       " (1.0015758, 'stream')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
